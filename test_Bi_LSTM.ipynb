{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "public-teddy",
   "metadata": {},
   "source": [
    "Under development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "resident-population",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "      <th>player_sub</th>\n",
       "      <th>main_player</th>\n",
       "      <th>commentary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89'</td>\n",
       "      <td>Yellow Card</td>\n",
       "      <td>na</td>\n",
       "      <td>K. Phillips</td>\n",
       "      <td>A hasty challenge from Kalvin Phillips now and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87'</td>\n",
       "      <td>Substitution</td>\n",
       "      <td>H. Kane</td>\n",
       "      <td>Carlos Vinícius</td>\n",
       "      <td>Harry Kane - who became a father this week - m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85'</td>\n",
       "      <td>Yellow Card</td>\n",
       "      <td>na</td>\n",
       "      <td>P. Højbjerg</td>\n",
       "      <td>Hojbjerg picks up a late booking here, as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78'</td>\n",
       "      <td>Substitution</td>\n",
       "      <td>T. Ndombèlé</td>\n",
       "      <td>Lucas Moura</td>\n",
       "      <td>Tottenham make their second change now, with N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76'</td>\n",
       "      <td>Substitution</td>\n",
       "      <td>H. Winks</td>\n",
       "      <td>M. Sissoko</td>\n",
       "      <td>Lloris gets a glance to this one and Ayling's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time         event   player_sub      main_player  \\\n",
       "0  89'   Yellow Card           na      K. Phillips   \n",
       "1  87'  Substitution      H. Kane  Carlos Vinícius   \n",
       "2  85'   Yellow Card           na      P. Højbjerg   \n",
       "3  78'  Substitution  T. Ndombèlé      Lucas Moura   \n",
       "4  76'  Substitution     H. Winks       M. Sissoko   \n",
       "\n",
       "                                          commentary  \n",
       "0  A hasty challenge from Kalvin Phillips now and...  \n",
       "1  Harry Kane - who became a father this week - m...  \n",
       "2  Hojbjerg picks up a late booking here, as the ...  \n",
       "3  Tottenham make their second change now, with N...  \n",
       "4  Lloris gets a glance to this one and Ayling's ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('event_data.pickle')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "packed-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import Data_Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ordered-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc = Data_Processor(data['commentary'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rolled-spectrum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_proc.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "stock-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seq = data_proc.seq\n",
    "targets = data_proc.targets\n",
    "seq_tr, seq_te, target_tr, target_te = train_test_split(seq[:100000], targets[:100000], \n",
    "                                                        test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "Epoch : 0, loss : 2.8287\n",
      "Epoch : 1, loss : 2.8289\n",
      "Epoch : 2, loss : 2.8241\n",
      "Epoch : 3, loss : 2.8206\n",
      "Epoch : 4, loss : 2.8143\n",
      "Epoch : 5, loss : 2.8054\n",
      "Epoch : 6, loss : 2.7936\n",
      "Epoch : 7, loss : 2.7861\n",
      "Epoch : 8, loss : 2.7724\n",
      "Epoch : 9, loss : 2.7525\n",
      "Epoch : 10, loss : 2.7463\n",
      "Epoch : 11, loss : 2.6804\n",
      "Epoch : 12, loss : 2.6960\n",
      "Epoch : 13, loss : 2.6282\n"
     ]
    }
   ],
   "source": [
    "args = {'batch_size' : 256,\n",
    "        'hidden_dim' : 128,\n",
    "        'window' : 100,\n",
    "        'init_method' : 'kaiming'}\n",
    "num_epochs = 50\n",
    "\"\"\"\n",
    "    Train the model\n",
    "\"\"\"\n",
    "from model import TextGen\n",
    "import torch \n",
    "\n",
    "gen = TextGen(args, data_proc.vocab_size)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(gen.parameters(), lr=0.001)\n",
    "\n",
    "batches = int(len(seq_tr) / args['batch_size'])\n",
    "print(batches)\n",
    "\n",
    "gen.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i in range(batches):\n",
    "        \n",
    "        try :\n",
    "            x_batch = seq_tr[i * args['batch_size'] : (i+1) * args['batch_size']]\n",
    "            y_batch = target_tr[i * args['batch_size'] : (i+1) * args['batch_size']]\n",
    "        except:\n",
    "            x_batch = seq_tr[i * args['batch_size'] :]\n",
    "            y_batch = target_tr[i * args['batch_size'] :]\n",
    "            \n",
    "        x = torch.from_numpy(x_batch).type(torch.LongTensor)\n",
    "        y = torch.from_numpy(y_batch).type(torch.LongTensor)\n",
    "#         print(x.shape, y.shape)\n",
    "        y_pred = gen(x)\n",
    "        \n",
    "        loss = torch.nn.functional.cross_entropy(y_pred, y.squeeze())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i == batches - 1 :\n",
    "            print(\"Epoch : {}, loss : {:.4f}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), 'weights/textgen_model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "excellent-greece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6405\n",
      "\\Pattern: \n",
      "\n",
      "nogbonna i \"\n",
      "nogbonna i                                                                                                     \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "gen.eval()\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "start = np.random.randint(0, len(seq_te)-1)\n",
    "print(start)\n",
    "pattern = seq_te[start]\n",
    "\n",
    "print(\"\\Pattern: \\n\")\n",
    "print(''.join([data_proc.idx2ch[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "full_pred = pattern.copy()\n",
    "\n",
    "for i in range(100):\n",
    "    pattern = torch.from_numpy(pattern).type(torch.LongTensor)\n",
    "    pattern = pattern.view(1,-1)\n",
    "    \n",
    "    prediction = gen(pattern)\n",
    "    prdiction = softmax(prediction)\n",
    "    \n",
    "    prediction = prediction.squeeze().detach().numpy()\n",
    "    \n",
    "    arg_max = np.argmax(prediction)\n",
    "    \n",
    "    pattern = pattern.squeeze().detach().numpy()\n",
    "    pattern = pattern[1:]\n",
    "    \n",
    "    pattern = np.append(pattern, arg_max)\n",
    "    \n",
    "    full_pred = np.append(full_pred, arg_max)\n",
    "\n",
    "print(''.join([data_proc.idx2ch[val] for val in full_pred]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-manitoba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a7",
   "language": "python",
   "name": "a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
